## 主题与分区

分区的划分不仅可以为Kafka提供了可伸缩性，水平扩展能力，还可以通过副本机制来为Kafka提供数据冗余以提高数据的可靠性，为了做到均匀分布，通常partition的数量通常是BrokerServer数量的整数倍。

**主题、分区、副本、日志关系：**

![](img\主题-分区-副本.png)	

### 分区

- 每个topic（逻辑名称）由一个或多个分区组成，分区是topic物理上的分组，在创建topic时被指定。

- 一个partition只对应一个Broke，一个Broke可以管理多个partition。

- 由消息在顺序写入，在同一个分区内的消息是有序的，在不同的分区间，kafka并不保证消息的顺序（所以kafka消息是支持跨分区的）。

- 同一个主题下，不同分区所包含的内容是不同的，每个消息被添加到分区当中时，会被分配一个偏移量（Offset），它是消息在分区当中的唯一编号，kafka通

  过offset来确保分区内的消息是顺序的，offset的顺序并不跨越分区。

- 要想保证消息顺序消息，需要将partion数目设为1。

#### 分区写入策略

所谓分区写入策略，即是生产者将数据写入到kafka主题后，kafka如何将数据分配到不同分区中的策略。常见的有三种策略：

- 随机策略：每次都随机地将消息分配到每个分区。
- 轮询策略：按顺序轮流将每条数据分配到每个分区中。轮询策略是默认的策略，除非有特殊的业务需求，否则使用这种方式即可。
- 按键（key）保存策略：当生产者发送数据的时候，可以指定一个key，计算这个key的hashCode值，按照hashCode的值对不同消息进行存储。

kafka默认是实现了两个策略，没指定key的时候就是轮询策略，有的话那就是按键保存策略。

#### 实现自定义分区

Kafka提供了两种让我们自己选择分区的方法：

- 第一种是在发送producer的时候，在ProducerRecord中直接指定，但需要知道具体发送的分区index，所以并不推荐。
- 第二种则是需要实现Partitioner.class类，并重写类中的partition(String topic, Object key, byte[] keyBytes,Object value, byte[] valueBytes, Cluster cluster) 方法，后面在生成kafka producer客户端的时候直接指定新的分区类就可以了。

### 副本

在kafka中，每个主题可以有多个分区，每个分区又可以有多个副本。这多个副本中，只有一个是leader，而其他的都是follower副本。仅有leader副本可以对外提

供服务。多个follower副本通常存放在和leader副本不同的broker中，通过这样的机制实现了高可用，当某台机器挂掉后，其他follower副本也能迅速”转正“，开

始对外提供服务。

#### AR ISR OSR

**AR**：分区中的所有副本统称为AR ( Assigned Replicas ) 。

**ISR**：所有与leader 副本保持一定程度同步的副本（包括leader 副本在内）组成ISR （In-Sync Replicas ) 。所谓“ 一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。

**OSR**: 与leader 副本同步滞后过多的副本（不包括leader 副本）组成OSR ( Out-of-Sync Replicas ），由此可见， AR=ISR+OSR 。

默认情况下， 当leader 副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader， 而在OSR集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变） 。

#### Kafka的副本有哪些作用

在kafka中，副本的目的就是冗余备份，且仅仅是冗余备份，所有的读写请求都是由leader副本进行处理的。follower副本仅有一个功能，那就是从leader副本拉取消息，尽量让自己跟leader副本的内容一致。

#### 为什么follow副本不对外提供服务

如果follower副本也对外提供服务那会怎么样呢？首先，性能是肯定会有所提升的。但同时，会出现一系列一致性问题。类似数据库事务中的幻读，脏读。比如你现在写入一条数据到kafka主题a，消费者b从主题a消费数据，却发现消费不到，因为消费者b去读取的那个分区副本中，最新消息还没写入。而这个时候，另一个消费者c却可以消费到最新那条数据，因为它消费了leader副本。



# 面试题

## 为什么不支持减少分区？

按照Kafka现有的代码逻辑而言，此功能完全可以实现，不过也会使得代码的复杂度急剧增大。

实现此功能需要考虑的因素很多，比如删除掉的分区中的消息该作何处理？如果随着分区一起消失则消息的可靠性得不到保障；如果需要保留则又需要考虑如何保留，直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于Spark、Flink这类需要消息时间戳(事件时间)的组件将会受到影响；如果分散插入到现有的分区中，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？

与此同时，顺序性问题、事务性问题、以及分区和副本的状态机切换问题都是不得不面对的。

反观这个功能的收益点却是很低，如果真的需要实现此类的功能，完全可以重新创建一个分区数较小的主题，然后将现有主题中的消息按照既定的逻辑复制过去即可。

